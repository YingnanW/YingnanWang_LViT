üß† Experimental Setup

All experiments were conducted using the PyTorch deep learning framework on a workstation equipped with an NVIDIA RTX 3090 Ti GPU (24 GB memory).
The GPU driver version was 535.183.01, and the CUDA version was 12.2, ensuring stable and efficient computation during both training and inference.

Training Configuration

Optimizer: Stochastic Gradient Descent (SGD)

Initial Learning Rate: 0.01

Batch Size: 32

Epochs: 150

Momentum: 0.9

Weight Decay (L2): 5 √ó 10‚Åª‚Å¥

Learning Rate Schedule: decayed by a factor of 0.8 every 10 epochs

This setup ensures smooth convergence and prevents overfitting while maintaining efficient training performance.
